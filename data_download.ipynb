{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed904974-b3cd-448b-8204-37829caffc66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pyesgf.search import SearchConnection\n",
    "os.environ[\"ESGF_PYCLIENT_NO_FACETS_STAR_WARNING\"] = \"on\"\n",
    "from geopy.geocoders import Nominatim\n",
    "from pyesgf.search import SearchConnection\n",
    "from dask.diagnostics import ProgressBar\n",
    "from utils import *\n",
    "\n",
    "wd = os.getcwd()\n",
    "models_dir=os.path.join(wd, 'data/models')\n",
    "reference_dir=os.path.join(wd, 'data/reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07741a-46e2-4f93-a38c-a7d2585a7942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city = 'Nairobi'\n",
    "latitude, longitude = get_coords(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8cea4-b372-48ab-b233-f15107cb0801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reanalysis reference dataset W5E5 can be downloaded from: https://data.isimip.org/datasets/96369b63-4fbf-4b90-8b58-79e5f50a385a/\n",
    "W5E5 = xr.open_mfdataset('data/W5E5/*.nc', engine = 'netcdf4').sel(lat=latitude, lon=longitude, method='nearest').convert_calendar(\"noleap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de8bec-28a8-4e81-97a1-64cc026272a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project='CMIP6'\n",
    "models = 'GFDL-ESM4,IPSL-CM6A-LR,MPI-ESM1-2-HR,MRI-ESM2-0'#,UKESM1-0-LL'\n",
    "variable_id = 'tas'\n",
    "table_id = 'day'\n",
    "experiment_id='historical'\n",
    "member_id='r1i1p1f1,r1i1p1f2' # f1 not available for UKESM1-0-LL\n",
    "\n",
    "connection = SearchConnection('https://esgf-data.dkrz.de/esg-search', distrib=True)\n",
    "query = connection.new_context(\n",
    "    latest = True,\n",
    "    project='CMIP6',\n",
    "    source_id=models,\n",
    "    experiment_id=experiment_id,\n",
    "    variable_id=variable_id,\n",
    "    table_id=table_id,\n",
    "    member_id=member_id,\n",
    "    data_node='esgf.ceda.ac.uk')\n",
    "\n",
    "print(\"Number of search results:\", query.hit_count)\n",
    "\n",
    "results = query.search()\n",
    "files=[]\n",
    "for i, result in enumerate(results):\n",
    "    print(\"Retrieving search results: \", result.dataset_id)\n",
    "    #print(result.json)\n",
    "    files.extend(list(map(lambda f : {'model': f.json['source_id'].pop(), 'dataset_id': result.dataset_id, 'filename': f.filename, 'url': f.opendap_url}, result.file_context().search())))    \n",
    "    \n",
    "files = list(files)\n",
    "files = pd.DataFrame.from_dict(files)\n",
    "files.drop_duplicates('filename')\n",
    "\n",
    "grouped_files = files.groupby('model', as_index=False).agg(list)\n",
    "grouped_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d887c9-67ce-431d-b685-1c0936af6899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load all files from url list for each model into xarray multi-file dataset\n",
    "\n",
    "start_time = W5E5.time[0].values\n",
    "end_time = W5E5.time[-1].values\n",
    "\n",
    "data={}\n",
    "for i,model in enumerate(grouped_files.model):\n",
    "    print(\"Selecting location...\")\n",
    "    print(\"Loading dataset: \", model)\n",
    "\n",
    "    data[model]=xr.open_mfdataset(grouped_files.iloc[i].url, chunks={'time': 120}).sel(\n",
    "        lat=latitude, lon=longitude, method='nearest').convert_calendar(\n",
    "        'noleap', align_on='year', missing='NaN').sel(\n",
    "        time=slice(start_time,end_time)).interpolate_na(method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b4fb3-0a5d-46e9-bc45-2bf99862b3b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(wd)\n",
    "for model, dataset in data.items():\n",
    "    print(\"Saving \", model, \"for selected city \", city)\n",
    "    identifier = '_'.join([model, city])\n",
    "    years, y_datasets = zip(*dataset.groupby(\"time.year\"))\n",
    "    fns=[identifier+f'_{y}.nc' for y in years]\n",
    "    paths=[os.path.join(models_dir,fn) for fn in fns]\n",
    "    with ProgressBar():\n",
    "        xr.save_mfdataset(y_datasets[-2:], paths[-2:], mode=\"w\",) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eba078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(wd)\n",
    "end_time = min([dataset.time[-1].values for dataset in data.values()])\n",
    "reference = W5E5.sel(time=slice(start_time,end_time))\n",
    "print(\"Saving reference for selected city \", city)\n",
    "identifier = '_'.join(['W5E5', city])\n",
    "years, y_datasets = zip(*reference.groupby(\"time.year\"))\n",
    "fns=[identifier+f'_{y}.nc' for y in years]\n",
    "paths=[os.path.join(reference_dir,fn) for fn in fns]\n",
    "with ProgressBar():\n",
    "    xr.save_mfdataset(y_datasets[-2:], paths[-2:], mode=\"w\",) # saving only 2 years of data for demo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
